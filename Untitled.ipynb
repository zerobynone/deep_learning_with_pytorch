{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0701bebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets,transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "is_cuda=False\n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "print(is_cuda)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f6f387",
   "metadata": {},
   "source": [
    "# Dataset 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "34decdbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_dataset = datasets.MNIST('data/',train=True,transform=transformation,download=True)\n",
    "test_dataset = datasets.MNIST('data/',train=False,transform=transformation,download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7084560",
   "metadata": {},
   "source": [
    "# Image 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1bcce315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(image):\n",
    "    image = image.numpy()[0]\n",
    "    mean = 0.13307\n",
    "    std = 0.3081\n",
    "    image = ((mean * image) + std)\n",
    "    plt.imshow(image,cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5ad3a1e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_data = next(iter(train_loader))\n",
    "plot_img(sample_data[0][31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4042be9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data[0][31].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33775a6",
   "metadata": {},
   "source": [
    "# 학습 Model 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d8f3dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10,20, kernel_size = 5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = F.relu(x)\n",
    "        ##x = nn.ReLU(nn.MaxPool2d(self.conv1(x), 2))\n",
    "        ##x = nn.ReLU(nn.MaxPool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1,320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "bf304329",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "if is_cuda:\n",
    "    model.cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e9dbbbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Net.forward of Net(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "print(model.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9bab01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##train 함수 생성\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X,y) in enumerate(dataloader): \n",
    "        ## enumerate는 list가 있을때 순서와 리스트의 값 전달\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        ## prediction & error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        \n",
    "        ## Backpropagation\n",
    "        optimizer.zero_grad()  ##이전의 기울기 값 초기화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch %100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f\"loss:{loss:>7f}[{current:>5d}/{size:5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b1a16959",
   "metadata": {},
   "outputs": [],
   "source": [
    "##test 함수 생성\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0,0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred,y).item()\n",
    "            correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c256bb",
   "metadata": {},
   "source": [
    "# Model 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "6d931d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "--------------------------\n",
      "loss:2.328921[    0/60000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-233-d52d4a288a3c>:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:2.083702[ 3200/60000]\n",
      "loss:0.513839[ 6400/60000]\n",
      "loss:0.237053[ 9600/60000]\n",
      "loss:0.255176[12800/60000]\n",
      "loss:0.362148[16000/60000]\n",
      "loss:0.456191[19200/60000]\n",
      "loss:0.244212[22400/60000]\n",
      "loss:0.187079[25600/60000]\n",
      "loss:0.435616[28800/60000]\n",
      "loss:0.278628[32000/60000]\n",
      "loss:0.330300[35200/60000]\n",
      "loss:0.118899[38400/60000]\n",
      "loss:0.149602[41600/60000]\n",
      "loss:0.115692[44800/60000]\n",
      "loss:0.108627[48000/60000]\n",
      "loss:0.122837[51200/60000]\n",
      "loss:0.069759[54400/60000]\n",
      "loss:0.158393[57600/60000]\n",
      "test Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.116982 \n",
      "\n",
      "Epoch 2\n",
      "--------------------------\n",
      "loss:0.247965[    0/60000]\n",
      "loss:0.080050[ 3200/60000]\n",
      "loss:0.094314[ 6400/60000]\n",
      "loss:0.122656[ 9600/60000]\n",
      "loss:0.373556[12800/60000]\n",
      "loss:0.082902[16000/60000]\n",
      "loss:0.046099[19200/60000]\n",
      "loss:0.009617[22400/60000]\n",
      "loss:0.063116[25600/60000]\n",
      "loss:0.102427[28800/60000]\n",
      "loss:0.027404[32000/60000]\n",
      "loss:0.046718[35200/60000]\n",
      "loss:0.029418[38400/60000]\n",
      "loss:0.016985[41600/60000]\n",
      "loss:0.053809[44800/60000]\n",
      "loss:0.098670[48000/60000]\n",
      "loss:0.274658[51200/60000]\n",
      "loss:0.078906[54400/60000]\n",
      "loss:0.058303[57600/60000]\n",
      "test Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.054489 \n",
      "\n",
      "Epoch 3\n",
      "--------------------------\n",
      "loss:0.033079[    0/60000]\n",
      "loss:0.036569[ 3200/60000]\n",
      "loss:0.008444[ 6400/60000]\n",
      "loss:0.029615[ 9600/60000]\n",
      "loss:0.065987[12800/60000]\n",
      "loss:0.135339[16000/60000]\n",
      "loss:0.024411[19200/60000]\n",
      "loss:0.025979[22400/60000]\n",
      "loss:0.018960[25600/60000]\n",
      "loss:0.041451[28800/60000]\n",
      "loss:0.023114[32000/60000]\n",
      "loss:0.017990[35200/60000]\n",
      "loss:0.190642[38400/60000]\n",
      "loss:0.126306[41600/60000]\n",
      "loss:0.107179[44800/60000]\n",
      "loss:0.060566[48000/60000]\n",
      "loss:0.017648[51200/60000]\n",
      "loss:0.007245[54400/60000]\n",
      "loss:0.007023[57600/60000]\n",
      "test Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.043556 \n",
      "\n",
      "Epoch 4\n",
      "--------------------------\n",
      "loss:0.073631[    0/60000]\n",
      "loss:0.035007[ 3200/60000]\n",
      "loss:0.016747[ 6400/60000]\n",
      "loss:0.037616[ 9600/60000]\n",
      "loss:0.001911[12800/60000]\n",
      "loss:0.031399[16000/60000]\n",
      "loss:0.006181[19200/60000]\n",
      "loss:0.046620[22400/60000]\n",
      "loss:0.060344[25600/60000]\n",
      "loss:0.067542[28800/60000]\n",
      "loss:0.000862[32000/60000]\n",
      "loss:0.095215[35200/60000]\n",
      "loss:0.079659[38400/60000]\n",
      "loss:0.073700[41600/60000]\n",
      "loss:0.073817[44800/60000]\n",
      "loss:0.180004[48000/60000]\n",
      "loss:0.003642[51200/60000]\n",
      "loss:0.022449[54400/60000]\n",
      "loss:0.001825[57600/60000]\n",
      "test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.040150 \n",
      "\n",
      "Epoch 5\n",
      "--------------------------\n",
      "loss:0.011874[    0/60000]\n",
      "loss:0.027040[ 3200/60000]\n",
      "loss:0.002397[ 6400/60000]\n",
      "loss:0.121347[ 9600/60000]\n",
      "loss:0.003998[12800/60000]\n",
      "loss:0.193161[16000/60000]\n",
      "loss:0.226447[19200/60000]\n",
      "loss:0.009910[22400/60000]\n",
      "loss:0.006167[25600/60000]\n",
      "loss:0.003015[28800/60000]\n",
      "loss:0.014435[32000/60000]\n",
      "loss:0.114161[35200/60000]\n",
      "loss:0.004113[38400/60000]\n",
      "loss:0.003008[41600/60000]\n",
      "loss:0.021394[44800/60000]\n",
      "loss:0.007342[48000/60000]\n",
      "loss:0.029405[51200/60000]\n",
      "loss:0.015023[54400/60000]\n",
      "loss:0.001361[57600/60000]\n",
      "test Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.038741 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n--------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
